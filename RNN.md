# RNN

1. 解决序列问题，后一时刻的数据跟前一时刻数据有关系
2. 为什么不能用(wx+b)，因为其没有学习到彼此之间的关系，收敛会很慢
3. 推导公式

# LSTM

1. 解决RNN存在的梯度爆炸和梯度
2. 为什么这三个门可以解决长依赖问题
   1. 有选择性的控制门开和关
   2. 当当前时刻与前一时刻连接不紧密的时候，可以令当前的ft尽可能小，it尽可能大，反之ft尽可能大。（重要的信息保留，次要的信息不要）
3. 推导公式
4. LSTM的不足
   1. GRU的产生，减少LSTM过多的参数
   2. 把LSTM的ft改成了（1-it）的思想

